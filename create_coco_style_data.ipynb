{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab --no-import-all\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = Path('./data/training/GT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in json_dir.iterdir():\n",
    "    if str(file).endswith('json'):\n",
    "        fdata = json.load(file.open())\n",
    "        data.extend(fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'annotations': [{u'class': u'Person',\n",
       "   u'height': 161.0,\n",
       "   u'width': 145.0,\n",
       "   u'x': 79.0,\n",
       "   u'y': 164.0},\n",
       "  {u'class': u'Person',\n",
       "   u'height': 204.0,\n",
       "   u'width': 152.0,\n",
       "   u'x': 280.0,\n",
       "   u'y': 148.0},\n",
       "  {u'class': u'Left Shoulder',\n",
       "   u'x': 183.59237462904284,\n",
       "   u'y': 234.89764096373426},\n",
       "  {u'class': u'Head', u'x': 140.8379860168, u'y': 271.11312308234},\n",
       "  {u'class': u'Head', u'x': 391.8266319533878, u'y': 256.275797115459},\n",
       "  {u'class': u'Right Shoulder',\n",
       "   u'x': 340.1478761714274,\n",
       "   u'y': 228.3184374301362},\n",
       "  {u'class': u'Right Elbow', u'x': 315.1556909981843, u'y': 251.6162371679052},\n",
       "  {u'class': u'Right Hand',\n",
       "   u'x': 329.13437084084575,\n",
       "   u'y': 304.14218566760263},\n",
       "  {u'class': u'Left Elbow',\n",
       "   u'x': 205.44423405123575,\n",
       "   u'y': 237.21396096637528},\n",
       "  {u'class': u'Left Hand', u'x': 177.0632780070444, u'y': 262.2061461396184},\n",
       "  {u'class': u'Right Shoulder',\n",
       "   u'x': 121.24598579893858,\n",
       "   u'y': 239.50561726785403},\n",
       "  {u'class': u'Right Elbow',\n",
       "   u'x': 121.8432566649432,\n",
       "   u'y': 261.00736844402047},\n",
       "  {u'class': u'Right Hand', u'x': 130.20504878900792, u'y': 292.6627243422655},\n",
       "  {u'class': u'Left Shoulder',\n",
       "   u'x': 415.700522739218,\n",
       "   u'y': 233.5329086078078},\n",
       "  {u'class': u'Left Hand', u'x': 381.0588125109498, u'y': 314.16447551843197}],\n",
       " u'class': u'image',\n",
       " u'filename': u'data/training/10_16_T1_K1/frame00325.jpg'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>class</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{u'y': 164.0, u'width': 145.0, u'x': 79.0, u'...</td>\n",
       "      <td>image</td>\n",
       "      <td>data/training/10_16_T1_K1/frame00325.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{u'y': 165.0, u'width': 159.0, u'x': 74.0, u'...</td>\n",
       "      <td>image</td>\n",
       "      <td>data/training/10_16_T1_K1/frame00431.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{u'y': 161.0, u'width': 151.0, u'x': 78.0, u'...</td>\n",
       "      <td>image</td>\n",
       "      <td>data/training/10_16_T1_K1/frame00636.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotations  class  \\\n",
       "0  [{u'y': 164.0, u'width': 145.0, u'x': 79.0, u'...  image   \n",
       "1  [{u'y': 165.0, u'width': 159.0, u'x': 74.0, u'...  image   \n",
       "2  [{u'y': 161.0, u'width': 151.0, u'x': 78.0, u'...  image   \n",
       "\n",
       "                                   filename  \n",
       "0  data/training/10_16_T1_K1/frame00325.jpg  \n",
       "1  data/training/10_16_T1_K1/frame00431.jpg  \n",
       "2  data/training/10_16_T1_K1/frame00636.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create coco-style data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data = {\"images\":[], \"annotations\":[], \"categories\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data[\"categories\"] = [{'supercategory': 'person',\n",
    "  'id': 1,\n",
    "  'name': 'person',\n",
    "  'keypoints': ['nose',\n",
    "   'left_eye',\n",
    "   'right_eye',\n",
    "   'left_ear',\n",
    "   'right_ear',\n",
    "   'left_shoulder',\n",
    "   'right_shoulder',\n",
    "   'left_elbow',\n",
    "   'right_elbow',\n",
    "   'left_wrist',\n",
    "   'right_wrist',\n",
    "   'left_hip',\n",
    "   'right_hip',\n",
    "   'left_knee',\n",
    "   'right_knee',\n",
    "   'left_ankle',\n",
    "   'right_ankle'],\n",
    "  'skeleton': [[16, 14],\n",
    "   [14, 12],\n",
    "   [17, 15],\n",
    "   [15, 13],\n",
    "   [12, 13],\n",
    "   [6, 12],\n",
    "   [7, 13],\n",
    "   [6, 7],\n",
    "   [6, 8],\n",
    "   [7, 9],\n",
    "   [8, 10],\n",
    "   [9, 11],\n",
    "   [2, 3],\n",
    "   [1, 2],\n",
    "   [1, 3],\n",
    "   [2, 4],\n",
    "   [3, 5],\n",
    "   [4, 6],\n",
    "   [5, 7]]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Annotation format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our annotations, we only have head(nose)(0), left shoulder(5), right shoulder(6), left elbow(7), right elbow(8), left wrist(9), right wrist(10), bb, arms crossed, both arms on table,\n",
    "both arms on body, one arm on body, one arm on table, leaning forward, leaning backward, upright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_ann_dict = {\"Head\":0, \"Left Shoulder\":5, \"Right Shoulder\":6, \"Left Elbow\":7, \"Right Elbow\":8, \"Left Hand\":9, \"Right Hand\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h, w = 424, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "i_ann = 0\n",
    "\n",
    "for i, item in pdata.iterrows():\n",
    "    #item = pdata.iloc[i]\n",
    "    #pprint(item)\n",
    "    fname = item['filename']\n",
    "    fname = fname.replace(\"Kinect\",\"depth\")\n",
    "    fname = fname.replace(\"ir\",\"ud\")\n",
    "    h, w, _ = cv2.imread(fname).shape\n",
    "    im = {\"height\":h, \"width\":w, \"file_name\":fname, \"id\":i}\n",
    "\n",
    "    coco_data[\"images\"].append(im)\n",
    "\n",
    "    annpd = pd.DataFrame(item['annotations'])\n",
    "    \n",
    "    eps = 15\n",
    "    for _, person in annpd[annpd[\"class\"]==\"Person\"].iterrows():\n",
    "        #print(person)\n",
    "        ann = {\"segmentation\":[], \"keypoints\":[], \"iscrowd\":0, \"num_keypoints\":17, \"area\":0, \"id\":None, \"image_id\":i, \"bbox\":[], \"category_id\":1}\n",
    "        ann[\"bbox\"] = [person[\"x\"], person[\"y\"], person[\"width\"], person[\"height\"]]\n",
    "        ann[\"area\"] = person[\"width\"] * person[\"height\"]\n",
    "        condition = (annpd[\"x\"] > person[\"x\"]-eps) & (annpd[\"x\"] < person[\"x\"]+person[\"width\"]+eps) & \\\n",
    "                    (annpd[\"y\"] > person[\"y\"]-eps) & (annpd[\"y\"] < person[\"y\"]+person[\"height\"]+eps)\n",
    "        \n",
    "        joints = annpd[condition & (annpd[\"class\"]!=\"Person\")]\n",
    "\n",
    "        kp = np.zeros(51, dtype=np.int)\n",
    "        for _, row in joints.iterrows():\n",
    "            if row[\"class\"] in joint_ann_dict:\n",
    "                idx = 3 * joint_ann_dict[row[\"class\"]]\n",
    "                kp[idx:idx+3] = int(row[\"x\"]), int(row[\"y\"]), 2\n",
    "        ann[\"keypoints\"] = kp.tolist()\n",
    "        ann[\"id\"] = i_ann\n",
    "        ann[\"image_id\"] = i\n",
    "\n",
    "        coco_data[\"annotations\"].append(ann)\n",
    "\n",
    "        i_ann += 1\n",
    "        #print(kp)\n",
    "\n",
    "        #print(joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'area': 23345.0,\n",
       "  'bbox': [79.0, 164.0, 145.0, 161.0],\n",
       "  'category_id': 1,\n",
       "  'id': 0,\n",
       "  'image_id': 0,\n",
       "  'iscrowd': 0,\n",
       "  'keypoints': [140,\n",
       "   271,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   183,\n",
       "   234,\n",
       "   2,\n",
       "   121,\n",
       "   239,\n",
       "   2,\n",
       "   205,\n",
       "   237,\n",
       "   2,\n",
       "   121,\n",
       "   261,\n",
       "   2,\n",
       "   177,\n",
       "   262,\n",
       "   2,\n",
       "   130,\n",
       "   292,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'num_keypoints': 17,\n",
       "  'segmentation': []},\n",
       " {'area': 31008.0,\n",
       "  'bbox': [280.0, 148.0, 152.0, 204.0],\n",
       "  'category_id': 1,\n",
       "  'id': 1,\n",
       "  'image_id': 0,\n",
       "  'iscrowd': 0,\n",
       "  'keypoints': [391,\n",
       "   256,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   415,\n",
       "   233,\n",
       "   2,\n",
       "   340,\n",
       "   228,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   315,\n",
       "   251,\n",
       "   2,\n",
       "   381,\n",
       "   314,\n",
       "   2,\n",
       "   329,\n",
       "   304,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'num_keypoints': 17,\n",
       "  'segmentation': []}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data['annotations'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "annfile = Path('annotations/keypoints.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(coco_data, open(str(annfile), mode='w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if annotation is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "#import skimage.io as io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "annfile = Path('annotations/keypoints.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(str(annfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgIds = coco.getImgIds(catIds=[1])\n",
    "imgs = coco.loadImgs(ids = imgIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/training/10_16_T1_K1/frame00325.jpg\n",
      "data/training/10_16_T1_K1/frame00431.jpg\n",
      "data/training/10_16_T1_K1/frame00636.jpg\n",
      "data/training/10_16_T1_K1/frame00891.jpg\n",
      "data/training/10_16_T1_K1/frame00940.jpg\n",
      "data/training/10_16_T1_K1/frame01070.jpg\n",
      "data/training/10_16_T1_K1/frame01232.jpg\n",
      "data/training/10_16_T1_K1/frame01241.jpg\n",
      "data/training/10_16_T1_K1/frame01278.jpg\n",
      "data/training/10_16_T1_K1/frame01288.jpg\n",
      "data/training/10_16_T1_K1/frame01324.jpg\n",
      "data/training/10_16_T1_K1/frame01348.jpg\n",
      "data/training/10_16_T1_K1/frame01739.jpg\n",
      "data/training/10_16_T1_K1/frame01888.jpg\n",
      "data/training/10_16_T1_K1/frame02208.jpg\n",
      "data/training/10_16_T1_K1/frame02287.jpg\n",
      "data/training/10_16_T1_K1/frame02362.jpg\n",
      "data/training/10_16_T1_K1/frame02529.jpg\n",
      "data/training/10_16_T1_K1/frame02541.jpg\n",
      "data/training/10_16_T1_K1/frame02704.jpg\n",
      "data/training/10_16_T1_K1/frame02819.jpg\n",
      "data/training/10_16_T1_K1/frame02835.jpg\n",
      "data/training/10_16_T1_K1/frame02853.jpg\n",
      "data/training/10_16_T1_K1/frame02937.jpg\n",
      "data/training/10_16_T1_K1/frame03206.jpg\n",
      "data/training/10_16_T1_K1/frame03263.jpg\n",
      "data/training/10_16_T1_K1/frame03350.jpg\n",
      "data/training/10_16_T1_K1/frame03403.jpg\n",
      "data/training/10_16_T1_K1/frame03531.jpg\n",
      "data/training/10_16_T1_K1/frame03708.jpg\n",
      "data/training/10_16_T1_K1/frame03777.jpg\n",
      "data/training/10_16_T1_K1/frame03783.jpg\n",
      "data/training/10_16_T1_K1/frame03833.jpg\n",
      "data/training/10_16_T1_K1/frame04090.jpg\n",
      "data/training/10_16_T1_K1/frame04143.jpg\n",
      "data/training/10_16_T1_K1/frame04210.jpg\n",
      "data/training/10_16_T1_K1/frame04311.jpg\n",
      "data/training/10_16_T1_K1/frame04415.jpg\n",
      "data/training/10_16_T1_K1/frame04480.jpg\n",
      "data/training/10_16_T1_K1/frame04528.jpg\n",
      "data/training/10_16_T1_K1/frame04717.jpg\n",
      "data/training/10_16_T1_K1/frame04863.jpg\n",
      "data/training/10_16_T1_K1/frame04965.jpg\n",
      "data/training/10_16_T1_K1/frame05177.jpg\n",
      "data/training/10_16_T1_K1/frame05188.jpg\n",
      "data/training/10_16_T1_K1/frame05625.jpg\n",
      "data/training/10_16_T1_K1/frame05674.jpg\n",
      "data/training/10_16_T1_K1/frame05955.jpg\n",
      "data/training/10_16_T1_K1/frame06002.jpg\n",
      "data/training/10_16_T1_K1/frame06378.jpg\n",
      "data/training/10_16_T1_K1/frame06555.jpg\n",
      "data/training/10_16_T1_K1/frame06656.jpg\n",
      "data/training/10_16_T1_K1/frame06894.jpg\n",
      "data/training/10_16_T1_K1/frame07360.jpg\n",
      "data/training/10_16_T1_K1/frame07539.jpg\n",
      "data/training/10_16_T1_K1/frame07620.jpg\n",
      "data/training/10_16_T1_K1/frame08120.jpg\n",
      "data/training/10_16_T1_K1/frame08143.jpg\n",
      "data/training/10_16_T1_K1/frame08188.jpg\n",
      "data/training/10_16_T1_K1/frame08262.jpg\n",
      "data/training/10_16_T1_K1/frame08337.jpg\n",
      "data/training/10_16_T1_K1/frame08428.jpg\n",
      "data/training/10_16_T1_K1/frame08437.jpg\n",
      "data/training/10_16_T1_K1/frame08438.jpg\n",
      "data/training/10_16_T1_K1/frame08445.jpg\n",
      "data/training/10_16_T1_K1/frame08471.jpg\n",
      "data/training/10_16_T1_K1/frame08553.jpg\n",
      "data/training/10_16_T1_K1/frame08869.jpg\n",
      "data/training/10_16_T1_K1/frame08938.jpg\n",
      "data/training/10_16_T1_K1/frame09068.jpg\n",
      "data/training/10_16_T1_K1/frame09135.jpg\n",
      "data/training/10_16_T1_K1/frame09154.jpg\n",
      "data/training/10_16_T1_K1/frame09298.jpg\n",
      "data/training/10_16_T1_K1/frame09651.jpg\n",
      "data/training/10_16_T1_K1/frame10197.jpg\n",
      "data/training/10_16_T1_K1/frame10225.jpg\n",
      "data/training/10_16_T1_K1/frame10751.jpg\n",
      "data/training/10_16_T1_K1/frame10761.jpg\n",
      "data/training/10_16_T1_K1/frame10770.jpg\n",
      "data/training/10_16_T1_K1/frame10788.jpg\n",
      "data/training/10_16_T1_K1/frame10793.jpg\n",
      "data/training/10_16_T1_K1/frame10794.jpg\n",
      "data/training/10_16_T1_K1/frame11311.jpg\n",
      "data/training/10_16_T1_K1/frame11392.jpg\n",
      "data/training/10_16_T1_K1/frame11983.jpg\n",
      "data/training/10_16_T1_K1/frame12156.jpg\n",
      "data/training/10_16_T1_K1/frame12196.jpg\n",
      "data/training/10_16_T1_K1/frame12294.jpg\n",
      "data/training/10_16_T1_K1/frame12378.jpg\n",
      "data/training/10_16_T1_K1/frame12457.jpg\n",
      "data/training/10_16_T1_K1/frame12606.jpg\n",
      "data/training/10_16_T1_K1/frame12833.jpg\n",
      "data/training/10_16_T1_K1/frame12964.jpg\n",
      "data/training/10_16_T1_K1/frame13163.jpg\n",
      "data/training/10_16_T1_K1/frame13201.jpg\n",
      "data/training/10_16_T1_K1/frame13254.jpg\n",
      "data/training/10_16_T1_K1/frame13333.jpg\n",
      "data/training/10_16_T1_K1/frame13380.jpg\n",
      "data/training/10_16_T1_K1/frame13440.jpg\n",
      "data/training/10_16_T1_K1/frame13479.jpg\n"
     ]
    }
   ],
   "source": [
    "dim = [2, 2]\n",
    "for i,img in enumerate(imgs):\n",
    "    fname = img['file_name']\n",
    "    #fname = fname.replace(\"Kinect\",\"depth\")\n",
    "    #fname = fname.replace(\"ir\",\"ud\")\n",
    "    print(fname)\n",
    "    I = cv2.imread(fname)\n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for ann in anns:\n",
    "        kp = ann['keypoints']\n",
    "        for j in range(17):\n",
    "            if kp[3*j+2]==2:\n",
    "                x, y = kp[3*j], kp[3*j+1]\n",
    "                cv2.circle(I,(x, y), 5, (0, 255, 0), 3)\n",
    "        bb = [int(f) for f in ann['bbox']]\n",
    "        cv2.rectangle(I, (bb[0], bb[1]), (bb[0]+bb[2], bb[1]+bb[3]), (255, 0, 0), 3)\n",
    "    ff = Path(fname).name\n",
    "    cv2.imwrite('checkim/{}.jpg'.format(ff), I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
